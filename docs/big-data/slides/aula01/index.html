<!DOCTYPE html>
<html>
  <head>
    <title>Arquitetura de Software</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Yanone Kaffeesatz';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 1.6em; }
      .remark-slide-content h2 { font-size: 1.1em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .remark-slide-content {
        font-size: 2.5em;
        padding-top: 0.2em;
        padding-left: 1em;
        padding-right: 1em;
      }
     .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      /* .inverse h1, .inverse h2 {*/
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
        font-size: 2em;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
    </style>
  </head>
  <body>
    <textarea id="source">
name: inverse
layout: true
class: center, middle, inverse
---
# Big Data - Aula 01
## Prof. Marc Queiroz
---
<iframe src="https://docs.google.com/document/d/e/2PACX-1vQPuXz_3cuhj2Iq7fP5GZShEgNx9q_T2u6JBRRZGDpJRQZrpoRe8QUBs0nj8RrrNdeRTzX3eg1_rA2U/pub?embedded=true"></iframe>
---
<object id="pdf_content" width="100%" height="700px" type="application/pdf" trusted="yes" application="yes" title="Assembly" data="https://docs.google.com/document/d/1nSH-nSt1p-r8-TJ2u0Q9gUGaxDBBJlc1_saPLpEJmmk/pub?embedded=true">
---
<!--object id="pdf_content" width="100%" height="1500px" type="application/pdf" trusted="yes" application="yes" title="Assembly" data="./bigdata.pdf?#view=FitH&scrollbar=1&toolbar=1&navpanes=1"-->
Você possivelmente já deve ter ouvido falar em algum momento nessa expressão tão popular atualmente: Big Data. Não é preciso muito esforço para encontrarmos uma notícia referente a esse termo nos dias atuais.
Seja em sites, jornais ou revistas das áreas de astronomia, biologia, educação, economia, política ou até culinária, podemos encontrar alguma publicação que relate o potencial e as características de Big Data. De fato, Big Data tem sido alvo de muita atenção no mundo dos negócios, no governo e no meio acadêmico.  
Podemos encontrar casos de uso em que Big Data permitiu a redução do número de fraudes, aumento de lucros, conquista de eleitores, redução de custos na produção, eficiência energética, aumento de segurança, entre outros benefícios tão almejados em diversos domínios. 

Muito embora o interesse esteja em alta, Big Data ainda é um termo incipiente, gerando incertezas sobre sua definição, características, aplicabilidade e desafios.
Quais dados fazem parte do contexto de Big Data? Qual a definição desse conceito? Como obter dados de diferentes fontes?  Como extrair valor a partir dos dados? Qual a infraestrutura necessária para criar uma solução de Big Data? Quais habilidades são necessárias para se atuar com Big Data?
Essas são apenas algumas das questões geradas por profissionais interessados nesse tema. Mas vamos com calma.  Para dar início ao esclarecimento dessas e de outras questões, você verá neste capítulo uma visão inicial sobre Big Data, que inclui a definição desse conceito e a descrição dos tipos de dados existentes nesse cenário.
Além dessas informações, será também apresentado um resumo dos processos em um projeto de Big Data e os mitos ainda existentes sobre o termo. Acredito que esse conteúdo servirá de base para a compreensão das demais questões, abordadas nos próximos capítulos.

1.1 POR QUE ESTAMOS NA ERA DOS DADOS

Atualmente, é comum usarmos nosso smartphone desde o primeiro instante em que acordamos, por meio de um alarme com nossa música favorita e por intervalos de tempos pré-determinados.  Nosso smartphone também pode nos avisar antecipadamente o horário de uma reunião, para que assim possamos evitar esquecimentos.
Podemos solicitar um serviço de transporte de passageiros por meio de um aplicativo. Se necessitamos de um documento que não esteja conosco, podemos facilmente acessar a internet e buscá-lo em um serviço de computação em nuvem para armazenamento de dados.
O exemplo também nos revela que a tecnologia está em constante evolução. Vinte anos se passaram e temos atualmente uma variedade de soluções capazes de facilitar nossas ações diárias, transformar o modo como nos comunicamos e gerar novas estratégias de negócios.
Por exemplo, você é capaz de imaginar como seria sua rotina sem os recursos tecnológicos disponíveis atualmente? Para auxiliar essa compreensão, verifique a tabela mais adiante e perceba como a tecnologia tem influência direta na maneira com que realizamos nossas atividades. Seja para lazer, viagens, compras ou trabalho, ela nos proporciona facilidades que antes eram inimagináveis.





E você sabe o que essa diversidade de serviços existentes tem em comum? A quantidade de dados que eles geram. Os avanços em hardware, software e infraestrutura de redes foram os responsáveis para que chegássemos à "era dos dados".
Nos anos 80 e 90, a maioria dos dados era armazenada em formato analógico. Discos de vinil, fitas de vídeo VHS e fitas cassete eram meios comuns para armazenar um dado. Tais recursos, comparados com o formato digital, eram frágeis e dificultavam o seu compartilhamento.
Embora esses recursos ainda existam, eles foram gradativamente sendo substituídos por recursos com tecnologias digitais. Isso é tão real que, um estudo feito pela revista Science apontou que, em 1996, somente 0.8% dos dados eram armazenados em formato digital, enquanto em 2007 a quantidade de dados digitais já era de 94%.
Essa transformação é facilmente percebida no mundo atual. Por exemplo, você saberia responder como as pessoas utilizam e armazenam uma música, um vídeo ou um documento nos dias atuais? Tenho certeza de que a resposta da grande maioria dos leitores envolve um dispositivo digital.
Comparando os recursos que temos atualmente com o que tínhamos alguns anos atrás, imagino que você possa estar pensando: como ocorreu essa transformação? Conforme apresentado na figura a seguir, uma série de fatores ocorreu com o passar dos anos, possibilitando o avanço tecnológico atual.
Certamente, a internet foi e continua sendo um dos fatores mais influentes no crescimento dos dados. Porém, além dela, outro fator que causou grande impacto foi a ampla adoção de dispositivos móveis nos últimos anos.
O poder de armazenamento, os recursos computacionais e o acesso à internet oferecidos por esses dispositivos ampliaram não somente a quantidade de dados únicos gerados, mas também a quantidade de vezes que eles eram compartilhados. Um vídeo gerado em um smartphone, por exemplo, pode facilmente ser compartilhado nas redes sociais, enviado por aplicativos de troca de mensagens e disponibilizado em diversos sites da Web.
Agora imagine esse compartilhamento sendo feito diariamente por parte dos 168 milhões de aparelhos de smartphones existentes somente no Brasil. Esse amplo compartilhamento é um dos fatores que levaram ao crescimento exponencial dos dados. Mídias sociais como o Facebook, Twitter, Pinterest e Instagram são exemplos de soluções que alavancaram esse compartilhamento e, consequentemente, a comunicação entre os usuários.




Figura 1.1: Principais fatores para o aumento do volume de dados

Além da crescente adoção de dispositivos móveis, dois outros fatores que contribuíram significativamente para o aumento do volume de dados foram o aumento do poder de processamento e a redução de custo de armazenamento de dados. Para exemplificar essas mudanças, temos o fato de que a primeira versão do iPhone, lançada em 2007, possuía uma capacidade de processamento muito superior a todo o sistema computacional utilizado para levar o homem à lua nos anos 60. Imagine então se compararmos esse sistema com a última versão do aparelho? Esse avanço é um dos resultados previstos pela Lei de Moore, que observou que a capacidade de processamento dos computadores dobraria aproximadamente a cada 18 meses.
Em relação ao armazenamento de dados, enquanto em 1990 o custo para armazenar 1 megabyte era de aproximadamente U$ 12.000, a média de custo atual é de apenas U$ 0,03. Ou seja, mesmo que empresas já identificassem possibilidades de extração de valor sobre uma vasta quantia de dados na década de 90, elas optavam muitas vezes por descartá-los, devido ao alto custo de armazenamento.
Ao passo que o volume de dados crescia e novas tecnologias habilitadoras para a geração desses dados eram criadas, empresas de diversos segmentos passaram a perceber o potencial que diferentes tipos de dados poderiam oferecer, seja para aperfeiçoar um processo, aumentar a produtividade, melhorar o processo de tomada de decisão, ou até mesmo para desenvolver novos produtos e serviços. A partir dessa visão, passam a surgir soluções que utilizam uma série de dados, internos e externos, para inúmeros propósitos.
Temos como exemplo a indústria varejista, que com a adoção de etiquetas de identificação por radiofrequência, ou RFID (do inglês Radio-Frequency IDentification), as empresas desse segmento passaram a otimizar seu processo de armazenamento, catalogação e transporte de mercadorias. Assim, tiveram uma maior agilidade no gerenciamento de seus processos. Na agricultura, temos a utilização de redes de sensores, que coletavam fluxos de dados em tempo real para fornecer suporte às ações referentes ao processo de plantação, cultivo e colheita.
Entretanto, mesmo havendo um avanço na quantidade de dados usada como apoio para as soluções, um estudo da EMC apontou que, em 2012, de todos os 643 exabytes de dados existentes no mundo digital, somente 3% foram utilizados. Ou seja, podemos concluir que ainda há um vasto número de oportunidades a serem exploradas.
Diante desse fato, pesquisadores consideram que estamos vivenciando o início de uma nova revolução industrial, na qual os dados passam a ser elementos chaves dessa mudança. Podemos concluir, portanto, que esse é o momento ideal para criarmos oportunidades a partir dos dados.


1.2 TODOS OS VS DE BIG DATA
É comum, ao ouvir pela primeira vez o termo Big Data, pensarmos que ele está unicamente relacionado a um grande volume de dados (o que é normal, já que o nome diz exatamente isso). Entretanto, o volume de dados não é sua única característica.  Além dessa, pelo menos outras duas propriedades devem ser consideradas: a variedade e a velocidade dos dados. Tais propriedades são popularmente denominadas os 3 Vs de Big Data, conforme apresentado na figura a seguir.





Figura 1.2: Os 3 Vs de Big Data

Volume
O atributo volume é a característica mais significativa no conceito de Big Data. Ele faz referência à dimensão sem precedentes do volume de dados.
Estimativas geradas por consultorias de TI relatam que, de todos os dados digitais existentes, 90% foram criados nos últimos dois anos. Mas você saberia responder qual é a origem para tantos dados? Confira a seguir algumas estatísticas que nos fazem perceber o que esse volume representa:
A cada segundo, cerca de 40.000 buscas são realizadas no Google.
A empresa Walmart manipula mais de 1 milhão de transações dos clientes por hora.
A rede social Facebook contabilizou em junho de 2016 uma média de 1.13 bilhão de usuários, 2.5 bilhões de compartilhamentos e 2.7 bilhões de “curtidas” diariamente.
A rede social de compartilhamento de fotos Instagram recebe atualmente cerca de 80 milhões de fotos por dia.
Em 2013, a plataforma de blogs WordPress relatou a quantidade de 42 milhões de comentários por mês, entre os 3.6 bilhões de páginas existentes na plataforma.
Qual a quantidade de espaço em disco necessária para armazenar todos esses dados? Esse volume gerou uma mudança de escala de petabytes para exabytes e zettabytes de dados nos últimos anos.
Segundo a consultora EMC, estima-se que, em 2013, havia 4.4 zettabytes (4.4 trilhões de gigabytes) de dados em todo o mundo, e que esse número deverá chegar a 44 zettabytes em 2020. Dada essa dimensão, a complexidade envolvida com essa mudança de escala torna-se difícil de ser mensurável por nós humanos.
Para tentarmos compreender o impacto desse crescimento, imagine se a população mundial que hoje (2016) possui 7.4 bilhões de pessoas aumentasse para 1 trilhão daqui 10 anos. Como prover, adaptar e gerir recursos para suportar esse crescimento populacional tão expressivo e em tão pouco tempo?
Analogamente falando, é isso que vem ocorrendo com os dados digitais na atualidade: um crescimento exorbitante, que requer mudanças de gerenciamento e controle em todos os âmbitos. No aspecto técnico, especificamente, mudanças são necessárias para superar desafios em relação à escalabilidade, eficiência, custo e complexidade para analisar os dados, uma vez que as tecnologias tradicionais não foram projetadas para suportar esse volume.
Uma dúvida frequente relacionada ao volume de dados é a identificação de quando um determinado conjunto de dados pode ser considerado Big Data. Será que necessito de uma solução de Big Data somente se possuo petabytes de dados? A resposta é não.  O tamanho dos dados é algo relativo quando se fala em Big Data. Por exemplo, uma clínica médica pode necessitar de soluções de Big Data para visualizar imagens de 30 gigabytes de dados. Por outro lado, uma empresa de biotecnologia pode necessitar de tecnologias capazes de analisar 300 gigabytes de dados genéticos; e uma empresa na área de entretenimento pode necessitar de uma solução capaz de processar 2 petabytes de dados.
Dessa forma, o que de fato define se o atributo volume requer uma tecnologia de Big Data é a limitação das ferramentas tradicionais para lidar com determinado volume de dados.

Variedade
O banco de dados relacional é o modelo de armazenamento de dados mais usado nos últimos 40 anos pelas corporações. Nesse modelo, dados são armazenados em formato de tabelas, de acordo com uma estrutura previamente definida.
Isso significa que, antes de armazenar alguma informação, é necessário definir a estrutura, a sequência, o tamanho e os tipos de dados em questão. Outra notável característica desse modelo é o suporte à propriedade ACID, que garante a integridade dos dados por meio dos seguintes recursos:
Atomicidade: garante que todas as alterações realizadas por uma transação serão efetivadas no banco de dados, ou nenhuma delas, caso ocorra algum problema. Ou seja, não há atualização parcial da transação.
Consistência: nesse caso é garantido que novas transações somente serão completadas se elas não ferirem nenhuma regra do banco de dados que possa torná-lo inconsistente.
Isolamento: propriedade que permite que os eventos em uma transação não interfiram nos eventos de outra transação concorrente.
Durabilidade: garante que o resultado de toda transação executada com sucesso deverá ser mantido no banco de dados, mesmo na ocorrência de falhas.
Embora seja muito eficiente e aplicado a diversos cenários, o banco de dados relacional é projetado para armazenar majoritariamente dados estruturados, isto é, dados com esquemas rígidos e adequados para o formato de tabelas. Isso se torna uma limitação para Big Data, uma vez que esse termo também inclui dados semiestruturados e não estruturados.
Podemos entender como dados semiestruturados aqueles que possuem uma estrutura pré-definida, porém não com o mesmo rigor dos dados relacionais. Essas estruturas são usadas normalmente apenas como um meio de marcação dos dados, como é o caso dos arquivos no formato JSON (JavaScript Object Notation) e XML (eXtensible Markup Language).
Na classe de dados não estruturados estão inclusos os vídeos, imagens, e alguns formatos de textos. Por não terem um formato que pode ser facilmente armazenado em tabelas, eles se tornam complexos para serem processados em ferramentas tradicionais de armazenamento e gerenciamento de dados.
Mesmo com a predominância do uso de sistemas de bancos de dados relacionais no mercado, há estimativas que, de todos os dados disponíveis globalmente, apenas 20% são considerados dados estruturados. Diante desse fato, onde 80% dos dados restantes devem ser armazenados?
Estes precisam de um modelo que ofereça flexibilidade quanto a sua estrutura, que não exija um esquema rígido previamente definido (como é exigido em bancos de dados relacionais), e que seja adequado para ambientes distribuídos, dependendo do volume. Esse fato trouxe a necessidade de não somente uma solução que fosse complementar aos bancos de dados relacionais, mas também de uma variedade de soluções e tecnologias, cada qual para atender às necessidades específicas de uma aplicação de Big Data.
Quando nos referimos à variedade, também cabe destacar a variedade de áreas das quais Big Data tem sido aplicado. O que antes era limitado a empresas do Vale do Silício, atualmente os dados e as tecnologias são utilizados em diversos segmentos, como por exemplo:
Na área governamental, com a utilização de tecnologias para rastrear os perfis dos eleitores na campanha do presidente dos Estados Unidos, Barack Obama;
No setor financeiro, com soluções na área de análise de risco e detecção de fraude;
Na área de transporte e automação, com o monitoramento de tráfego e rastreamento de carga;
No setor de varejo, com a possibilidade de gerar ofertas baseadas na análise de vendas e no perfil do consumidor;
Nas diversas possibilidades na área de marketing, por meio da análise de redes sociais;
Na área de seguros, com a possibilidade de ofertas de planos baseados no comportamento do segurado.
Ou seja, há uma diversidade de dados sendo utilizada por uma variedade de soluções, cada qual com necessidades específicas.  Embora a variedade dos dados seja algo já explorado, ainda são poucas as empresas que conseguem criar soluções eficientes por meio dessa abordagem, principalmente em relação à integração de tais dados.
Por não ser explicitamente claro o valor que essa variedade de dados oferece, ainda é comum que muitas fontes de dados e possibilidades de análises sejam simplesmente ignoradas. O pensamento de que somente os dados transacionais são suficientes para o processo de tomada de decisão ainda existe, porém essa mudança vem ocorrendo aos poucos.


Velocidade
Além dos desafios impostos pelo volume e variedade dos dados, Big Data também faz referência a outra propriedade: a velocidade com que os dados são coletados, analisados e utilizados.  Imagine, por exemplo, que um cliente receba recomendações de um produto em um e-commerce somente uma semana após ele ter realizado uma compra. Embora tal recomendação ainda possa gerar um efeito positivo, é muito provável que o impacto teria sido superior, caso essa tivesse sido realizada no momento da compra.  Esse é um exemplo que nos mostra que os dados coletados perdem seu valor com o decorrer do tempo. Por exemplo, um relatório atualizado a cada 5 minutos sobre a quantidade de produtos vendidos e em estoque oferece muito mais eficácia no gerenciamento de vendas se comparado a um relatório atualizado semanalmente.
Uma empresa que compreende bem o benefício da velocidade é a varejista Amazon, que adota um mecanismo de precificação dinâmica, podendo chegar a atualizar os valores de seus produtos a cada 10 minutos, de acordo com a análise da demanda em tempo real de seus suprimentos. O fator velocidade está se tornando tão importante, ao ponto que empresas que não conseguirem agilizar o tempo de análise dos dados terão dificuldades em se manterem competitivas no mercado.
Além da velocidade de análise, o fator velocidade também está relacionado à rapidez com que os dados estão sendo gerados.  Estatísticas mencionam que, em apenas 1 minuto, mais de 2 milhões de pesquisas são realizadas no buscador Google, 6 milhões de páginas são visitadas no Facebook e 1.3 milhão de vídeos são vistos no YouTube. Em complemento, temos os inúmeros aplicativos que mantém seus serviços em execução 24 horas por dia e os sensores que geram dados continuamente a cada segundo.

Resumos dos 3 Vs
Diante dos fatos apresentados, cabe ressaltar que, quando nos referimos a Big Data, o importante não é somente a mudança quantitativa dos dados. É possível que uma organização tenha grandes conjuntos de dados e não faça nenhuma análise relevante sobre deles. A grande mudança está no valor que se consegue obter a partir do volume, variedade e velocidade de dados, ou seja, uma mudança qualitativa.
Por exemplo, duas empresas de telecomunicação podem obter milhões de registros de arquivos CDR (Call Detail Record).  Entretanto, só terá vantagens a empresa que conseguir gerar conhecimento a partir desses dados e utilizá-lo para diferentes aplicações, tais como a segmentação dos assinantes, identificação de fraude e predição de falhas.
A partir dos três atributos mencionados, podemos chegar à seguinte definição de Big Data criada pela consultora Gartner: "Big Data faz referência não somente ao volume, mas também à variedade e à velocidade de dados, necessitando de estratégias inovadoras e rentáveis para extração de valor dos dados e aumento da percepção".
Ou seja, precisamos ter consciência de que Big Data exige a quebra de paradigmas. Precisamos lidar com novos tamanhos de dados, novas velocidades, novas tecnologias e novos métodos de análise de dados. Não há como atuar com Big Data estando resistente a mudanças.
Mas então Big Data faz referência somente ao volume,
variedade e velocidade dos dados? Não. Além dos 3 Vs, você pode encontrar outros atributos utilizados na definição de Big Data.  Alguns pesquisadores adotam os 5 Vs, em que são acrescentados os atributos valor e veracidade dos dados.
O valor é um atributo que faz referência ao quão valioso e significativo um dado pode ser em uma solução. Por exemplo, qual o valor dos dados de mídias sociais para uma solução de Big Data no departamento de marketing de uma empresa? É importante fazer essa análise de valor para se determinar quais dados serão priorizados pela empresa.
O atributo veracidade está relacionado à confiabilidade dos dados. Pelo fato de que Big Data está inserido em um contexto de dados em grande volume e variedade, é comum a existência de dados inconsistentes. Assim, a veracidade refere-se ao quão confiável é um conjunto de dados usado em uma solução de Big Data.
Além desses atributos, ainda há outros Vs que você pode encontrar em suas pesquisas. Mas não se preocupe, pois os 3 Vs formam a base necessária para o conhecimento de Big Data.  Para dar continuidade ao entendimento sobre Big Data, a seguir serão apresentados exemplos de tipos de dados utilizados nesse contexto. Aproveite a leitura para já tentar identificar quais soluções podem ser criadas na área em que você atua, a partir dessa variedade de dados.

1.3 DADOS GERADOS POR HUMANOS
Na seção anterior, vimos que atualmente os dados são gerados por inúmeras fontes. Podemos classificar os dados em diferentes categorias, tais como dados internos, externos, textuais e transacionais.
Para simplificar nosso entendimento, os dados serão aqui apresentados a partir das seguintes categorias: dados gerados por humanos e dados gerados por máquinas. O conteúdo gerado em cada categoria implica em funcionalidades e características específicas que devem ser consideradas em um projeto.
Dados gerados por humanos são aqueles em que o conteúdo foi gerado a partir do pensamento de uma pessoa, na qual a propriedade intelectual está integrada ao dado. Além disso, podemos entender também como sendo os dados que refletem a interação das pessoas no mundo digital.
Atualmente, grande parcela dos dados gerados por humanos é oriunda de mídias sociais, onde usuários podem publicar o que pensam sobre algo, gerar debates, publicar suas preferências e suas emoções. Essas informações são geradas em formatos de texto, imagem, áudio e vídeo, resultando em uma base de dados diversificada e volumosa.
Se somarmos esses dados aos que são gerados pelos aplicativos de trocas de mensagens, como o WhatsApp, Snapchat e os dados de videoconferência por meio de aplicativos como o Skype, já temos um ritmo acelerado da quantidade de dados que nós, humanos, geramos diariamente. Mas esses não são os únicos que nós geramos.


Além das mídias sociais, sempre que estamos conectados à internet geramos diversos outros tipos de dados. Temos, por exemplo, os blogs, com conteúdo gerado e compartilhado por milhões de pessoas. Temos ainda as avaliações sobre produtos e serviços que geramos em sites de e-commerce, como a Americanas.com e Amazon.com, e os serviços de crowdsourcing como o TripAdvisor.
Essas informações são usadas para gerar recomendações aos usuários, para avaliar o nível de satisfação com um determinado serviço ou produto, e para segmentar os usuários de acordo com os perfis analisados. Dessa forma, dependendo da análise realizada sobre tais dados, a varejista Walmart pode, por exemplo, descobrir quais são as preferências de seus clientes, e a empresa de streaming de vídeos Netflix pode descobrir quais filmes recomendar para seus usuários.
Além dos dados já citados, não podemos esquecer daqueles que geramos para documentar algo. Documentos de texto, e-mails, apresentações de slides e planilhas eletrônicas são geradas diariamente para documentar alguma informação, tanto pessoal quanto referente aos negócios de uma empresa. Entretanto, pouco ainda se faz para extrair valor a partir desses dados.  Por exemplo, na sua empresa é feito algum tipo de análise sobre esse conjunto de dados? São poucas as que gerenciam essas informações, possibilitando a descoberta de padrões e melhoria dos processos.
Os sites colaborativos também representam uma parcela significativa de dados gerados por humanos. Dois exemplos notórios são o Wikipédia, a maior enciclopédia online com conteúdo gerido por usuários; e o Flickr, um serviço online de compartilhamento de imagens. Porém, você pode encontrar dados gerados por humanos em inúmeros sites com propostas similares a esses exemplos.
Todos os exemplos aqui mencionados são considerados dados explicitamente gerados por humanos, em que o usuário possui o conhecimento de quando e como eles são criados. Entretanto, muitos serviços atualmente capturam dados de nós, humanos, implicitamente, ou seja, sem que saibamos que eles estão sendo capturados.
Temos, por exemplo, a relação das URLs que visitamos, os tamanhos de tela dos dispositivos que utilizamos, a descrição desses dispositivos, nossa localização, entre outras informações.  Ou seja, são dados oriundos de eventos realizados por nós, porém geradas automaticamente por máquinas, conforme veremos na sequência.

1.4 DADOS GERADOS POR MÁQUINAS
Enquanto dados gerados por humanos são aqueles oriundos do pensamento de uma pessoa, podemos definir dados gerados por máquinas como dados digitais produzidos por processos de computadores, aplicações e outros mecanismos, sem necessitar explicitamente de intervenção humana.
Quando utilizamos uma aplicação Web para fazer o upload de uma foto ou vídeo, para publicar um comentário, jogar ou assistir um vídeo via streaming, não temos muita percepção da infraestrutura necessária para suportar tais serviços. Quantos servidores são necessários para armazenar todos os dados que geramos nessas ações? É difícil obtermos essa informação exata.  Entretanto, dado o conhecimento da quantidade de dados gerados diariamente e a imensa quantidade de aplicações Web disponíveis, podemos facilmente concluir que são necessários milhares de servidores em todo o mundo para suportar essa demanda. Além de servidores, a infraestrutura de um data center é formada por diversos equipamentos, como cabos, roteadores e switches.
Para monitorar o status desses componentes, são gerados registros de log sempre que um evento ocorre. Uma vez que tais data centers ficam em execução 24 horas por dia, 7 dias na semana, milhares de registros são gerados ao final de um curto período.  Apesar da grande quantidade, é importante manter esses dados, pois a partir deles pode ser possível obter informações úteis aos provedores de serviços.
Por exemplo, arquivos de log podem conter as URLs visitadas por um usuário de um e-commerce, que se forem analisadas, podem prover informações sobre quais compras não foram concluídas e possíveis motivos por isso ter ocorrido. De outra forma, os arquivos de log também podem ser úteis para descobrir a causa de problemas ocorridos e identificar padrões que permitam prever a existência de ocorrências similares no futuro.
Além dos já mencionados, os dados gerados por máquinas têm sido amplamente gerados com o advento da tecnologia de comunicação máquina a máquina (Machine-to-Machine — M2M).  Uma tecnologia integrada ao paradigma de Internet das Coisas (Internet of Things — IoT) que permite a comunicação direta entre dispositivos.
Nesse paradigma, além dos computadores, demais objetos passam a fazer parte da infraestrutura global da internet, gerando, consumindo e interagindo com outras pessoas e objetos, no mundo físico e virtual. Temos como exemplo desses objetos as etiquetas RFID, os sensores, os atuadores, os vestíveis e os smartphones.
Há uma projeção feita pela Cisco que o número de objetos inseridos no contexto de IoT será em torno de 50 bilhões até o ano de 2020. Dada essa quantidade, um relatório da International Data Corporation (IDC) prevê que, em 2020, os dados gerados por máquinas representarão 42% de todos os dados existentes.  Embora os dados usados no contexto de IoT sejam valiosos, o processo de abstração, contextualização, análise e gerenciamento desses dados ainda é considerado um grande desafio. Por esse motivo, além de armazenar os dados gerados, é importante armazenar o seu significado, como informações sobre o tempo e espaço em que eles foram produzidos. A fusão dos dados gerados por diferentes objetos também é necessária para aferir novos conhecimentos, tornando assim o ambiente mais inteligente.
Outros dados fabricados por máquinas e muito usados atualmente no universo de Big Data são os dados genéticos.  Temos, por exemplo, a bioinformática, uma área multidisciplinar que tem como foco o estudo da aplicação de técnicas computacionais e matemáticas à (bio)informação, na qual pesquisadores manipulam grandes volumes de dados genéticos para descobrir padrões ocultos sobre eles.

O surgimento de tecnologias de Big Data e o baixo custo nos últimos anos para realizar o sequenciamento de DNA resultou em significantes avanços de pesquisa nessa área. Isso possibilitou a realização de análises que até então eram inviáveis.
Para mensurarmos o volume de dados existente nesse contexto, podemos tomar como referência nosso DNA. Uma sequência de pares do DNA humano possui 3.2 bilhões de pares de base ACTG (Adenina, Citosina, Timina e Guanina). Isso apenas de um ser.
Entretanto, já existem projetos como o The 1000 Genomes Project (http://www.1000genomes.org/), que por meio do sequenciamento em larga escala, agregaram centenas de genomas humanos em 2012, resultando em um extenso catálogo de variação genética. Demais estudos já permitem obter sequências de genomas de milhões de espécies de plantas e animais, fornecendo percepções para estudos na área biológica, ambiental, de energia e agricultura.
Os exemplos apresentados formam apenas uma parcela dos dados que podemos conceituar como dados gerados por máquinas.  A cada momento, milhões de diferentes tipos de dados digitais são gerados por recursos tecnológicos, resultando em uma fonte quase inesgotável de informação. Somados aos dados gerados por humanos, podemos perceber quantas possibilidades nos são apresentadas no universo de Big Data.

1.5 MITOS SOBRE BIG DATA
Por se tratar de um conceito ainda recente, ainda há muitas dúvidas sobre o que é verdade e o que é mito sobre Big Data. Por esse motivo, antes de darmos continuidade ao conteúdo, confira a seguir algumas informações que você já pode ter escutado em algum momento, mas que não retratam a realidade.  Big Data engloba somente dados não estruturados. — Com o crescente volume de dados nos últimos anos, o banco de dados relacional precisou ser complementado com outras estruturas, devido principalmente à escalabilidade e flexibilidade de armazenamento. Entretanto, os dados relacionais continuam sendo valiosos e são muito utilizados em soluções de Big Data. O que mudou de fato foi a inclusão de mais tipos de dados, além dos estruturados.
Big Data refere-se somente a soluções com petabytes de dados. — Embora o volume de dados seja o fator que impulsionou o fenômeno Big Data, aplicações que utilizam conjuntos de dados em uma escala menor do que petabytes também podem se beneficiar das tecnologias de Big Data. Afinal, o mais importante nessas aplicações é a capacidade de extrair valor dos dados.
Big Data é aplicado somente às empresas do Vale do Silício. — Quando se fala sobre Big Data, é comum que sejam usados como exemplos as grandes empresas de serviços Web do Vale do Silício, tais como o Facebook, Twitter e Netflix. Embora elas tenham sido as primeiras a serem desafiadas com o grande volume, variedade e velocidade de dados, atualmente empresas de diversos outros domínios, como agricultura e varejo, também necessitam de tecnologias de Big Data para atender suas necessidades em relação aos dados que elas adquirem.
Big Data é aplicado somente em grandes empresas. — Ainda há essa percepção de que Big Data oferece valor somente para grandes organizações. Entretanto, pequenas e médias empresas também podem obter vantagem competitiva por meio de soluções de Big Data, oferecendo uma melhor experiência aos seus clientes, otimizando processos, reduzindo custos ou criando novos produtos e serviços orientados por dados.
Big Data requer o uso de dados externos. — Embora a adoção de dados de diferentes fontes seja uma prática muito adotada em soluções de Big Data, a aquisição de dados externos não é um requisito obrigatório. Na verdade, a sugestão para quem inicia um projeto de Big Data é buscar extrair valor primeiramente dos dados internos, para somente depois ampliar sua jornada utilizando dados de terceiros.
As tecnologias de Big Data já estão bem estabelecidas.  — Infelizmente (ou felizmente, se pensarmos nas oportunidades) não. Estamos vivendo um momento de transição de soluções tradicionais para tecnologias de Big Data. Portanto, se você for atuar em um projeto de Big Data, deve ficar sempre atento ao surgimento de novas versões das tecnologias adotadas, bem como verificar o surgimento de tecnologias complementares presentes no mercado.

1.6 UM MUNDO DE OPORTUNIDADES
Os exemplos apresentados nos mostram a diversidade de dados que existe atualmente. São dados de diferentes formatos, gerados em períodos e locais diferentes e por diferentes agentes. Mas uma vez que esses dados existem, o que podemos fazer com eles? Eis a grande questão.
Por exemplo, o que um registro de log pode fornecer de informação para meu e-commerce? O que posso fazer com os dados coletados de redes de sensores? O que as opiniões das redes sociais podem me fornecer de valioso? São empresas capazes de responder essas questões que estão potencializando seu negócio a partir de Big Data.
Mas será que preciso capturar todos esses dados para obter oportunidades com as tecnologias de Big Data? A resposta é não.  Muitas empresas já possuem quantidades significativas de dados e não as utilizam para obtenção de valor. Isso pode ocorrer por diversos aspectos em relação à manipulação dos dados. Por exemplo, oportunidades podem ser desperdiçadas pelo fato de que: Os dados não estão integrados. — Eles já são gerados pela empresa, mas por serem armazenados em diferentes sistemas e bases, não fornecem uma visão ampliada da solução de um problema.

Os dados demoram para ser analisados. — Nesse caso, gasta-se muito tempo no processo de análise dos dados, o que impede a identificação de informações no momento adequado.
Os dados não estão categorizados. — São casos em que os registros dos conjuntos de dados estão armazenados de diferentes maneiras, sem uma padronização dos campos, impedindo a identificação de anomalias e categorias existentes nos dados.  Os dados estão obscuros. — Casos em que só é possível obter informações a partir da análise de outros dados, como a identificação de padrões em streaming de vídeos, extração de informações em imagens e dados manuscritos.
Os dados não são usados na tomada de decisão. — São os que poderiam ser utilizados no processo de apoio à tomada de decisão, mas por não serem integrantes dos dados tradicionais da empresa, são descartados desse processo.
Os dados não são visualizados com clareza. — São situações nas quais os dados já são armazenados, porém não são analisados e apresentados de maneira efetiva para gerar percepções sobre eles.
Os dados não são medidos. — Refere-se a casos nos quais não se utilizam as métricas que os dados podem fornecer para a compreensão de um fato, até então, imperceptível.

Perceba que muitas empresas já têm a possibilidade de aperfeiçoar a utilização de seus dados, mas não conseguem por fatores como os descritos anteriormente. Medidas como a adoção de novas tecnologias ou uma nova forma de organização dos dados podem trazer grandes transformações em relação à utilização de dados para extração de valor.
Um exemplo é o que ocorreu com uma sede da Microsoft que possuía mais de mil funcionários. Com foco em traçar um plano de eficiência energética dentro da sede, a empresa possuía mais de 30 mil sensores gerando dados a todo instante sobre o consumo de energia.
O problema é que esses dados estavam espalhados em diversos sistemas da empresa, impedindo que ela tivesse uma visão ampla do consumo energético. Com a integração dos dados em um sistema único de eficiência energética, a empresa conseguiu identificar, entre outras análises, salas que consumiam energia sem ter a necessidade.
Como resultado, essa integração evitou um gasto de 60 milhões de dólares com investimento em tecnologias de eficiência energética. Perceba que, nesse caso, a empresa já gerava os dados necessários, o problema estava no modo com que eles estavam organizados.
Outro exemplo é o da Pirelli, empresa multinacional do setor de produção de pneus. Essa empresa estava tendo problemas para entregar seus produtos aos milhares de clientes no tempo correto, sem que houvesse atraso nos pedidos.
Um dos fatores que ocasionavam esses atrasos era a demora para a geração dos relatórios, impedindo os analistas de terem uma visão atualizada da situação do estoque e dos pedidos de vendas. A solução nesse caso foi utilizar uma tecnologia de Big Data que agilizasse o processo de geração de relatórios para os analistas.  Com essa medida, utilizando uma tecnologia de processamento em memória, relatórios que demoravam um dia inteiro para serem atualizados passaram a ser gerados em 10 minutos. Essa otimização fez com que a empresa tivesse menos desperdício em sua produção, entregasse os produtos de acordo com o prazo e otimizasse o processo de entrega.
Perceba que a empresa já analisava os dados obtidos, mas ela aumentou o valor dos dados agilizando o processo de análise. Esses casos denotam como os dados podem gerar diferentes oportunidades, dependendo da maneira com que são usados.  Uma das famosas frases relacionadas a Big Data é: "Big Data é o novo petróleo". Podemos pensar que isso é uma analogia coerente, dado que, assim como o petróleo, o maior valor é obtido após um processo de refinamento, ou seja, após a transição de dados brutos para um determinado produto. Entretanto, diferente do petróleo, os dados não são recursos escassos.
Um mesmo conjunto de dados que utilizamos para uma determinada estratégia pode ser usado em outra, sem perda nesse processo. Temos assim um leque de oportunidades a serem criadas.
Para tornar mais compreensível o entendimento sobre como essas estratégias podem resultar em oportunidades, na tabela adiante é apresentado alguns exemplos de soluções de Big Data, criadas por diferentes áreas de conhecimento. A área de cuidados de saúde é um exemplo notável.
Com o uso da tecnologia móvel, de dispositivos de IoT e da computação em nuvem, surgem soluções inovadoras para melhorar o cuidado de pacientes, tais como o monitoramento em tempo real do paciente e a previsão de demanda para os leitos do hospital. Soluções de Big Data também estão sendo usadas para identificar padrões em bases de dados históricas de doenças, permitindo acelerar e aperfeiçoar o diagnóstico realizado por uma equipe médica.

Os exemplos apresentados demonstram diferentes formas de como Big Data pode ser utilizado. Entretanto, projetar uma solução não é uma tarefa simples, existindo diversos percalços no decorrer de seu desenvolvimento.

Para que se possa chegar à etapa final de um projeto de Big Data, existe um conjunto de etapas que deverão ser executadas. De forma bastante resumida, descrevo uma sequência de passos existentes nesses projetos.
1. O primeiro passo a ser feito (e que muitas vezes ainda é descartado) é identificar quais perguntas se deseja responder com os dados. É nesse momento que deve ser determinado quais informações pretende-se extrair de um conjunto de dados. Essa tarefa não é fácil. Necessita de pessoas com pensamento analítico, capazes de identificar possíveis análises sobre diferentes dados. Quanto mais claras forem as respostas obtidas nessa fase, mais fácil se torna a execução das fases seguintes.
2. O próximo passo refere-se a captura e armazenamento dos dados. Devemos então identificar quais fontes serão utilizadas e como os dados serão capturados. Para isso, torna-se necessário identificar a solução adequada para armazenar cada tipo de dado. É nessa fase que identificamos a ordem com que os dados serão usados, definimos quais campos serão utilizados e quais informações devem ser tratadas.
3. Estando os dados armazenados, passamos para a fase de processamento e análise. Tecnologias de Big Data são cruciais nessa fase, para oferecer escalabilidade e desempenho para a aplicação. É nessa fase também que se determina qual algoritmo de análise de dados será usado.  Inserem-se aqui os mecanismos de aprendizado de máquina, métodos estatísticos, fundamentos matemáticos e mineração de dados.
4. Por fim, Big Data também inclui a etapa de visualização de dados, em que são utilizadas técnicas de criação de gráficos dinâmicos e interativos. Essa etapa pode também ser usada em conjunto com a fase de análise de dados, para facilitar o processo de descoberta dos dados.
Nos demais capítulos, será abordada com maior detalhe cada uma dessas etapas para a implementação de um projeto de Big Data. É importante ressaltar, porém, que os passos descritos são referentes a uma parte das atividades apenas, havendo inúmeras outras ações necessárias para a execução do projeto, como a aquisição de profissionais habilitados, preparação da infraestrutura e análise de custo. Porém, acredito que o escopo abordado no livro fornecerá uma visão significativa sobre projetos de Big Data.

1.7 CONSIDERAÇÕES
Este capítulo teve como objetivo apresentar a base inicial do conceito de Big Data. Podemos descobrir que, além do volume, Big Data também faz referência à grande variedade e velocidade de dados (formando os famosos 3 Vs de Big Data).
Podemos encontrar outros "Vs" na literatura, tais como o valor e a veracidade dos dados, porém são o volume, variedade e velocidade que formam a base de Big Data. Ainda sobre a contextualização de Big Data, foi apresentado que tanto dados gerados por humanos quanto por máquinas são significantes e oferecem diferentes percepções quando analisados.

Faça uma reflexão sobre a área em que atua, pode ser beneficiada a partir de Big Data. Para auxiliar, sugiro que tente responder às seguintes questões:
1. Quais dados estruturados, semiestruturados e não estruturados são gerados pela minha empresa ou na área que atuo?
2. Como os dados gerados por humanos e por máquinas são utilizados?
3. Há problemas no tempo gasto para analisar os dados?
4. Existem dados que poderiam agregar valor à empresa se fossem adquiridos?
---
layout: false
class: inverse, middle

Usabilidade

Qualquer idiota pode tornar algo complexo; é preciso um gênio para fazer algo simples.

- Albert Einstein
---
layout: false
class: inverse, middle

Usabilidade se preocupa com a facilidade com que o usuário realiza uma tarefa desejada e com o tipo de suporte que o sistema fornece. Ao longo dos anos, o foco na usabilidade mostrou-se uma das maneiras mais baratas e fáceis de melhorar a qualidade de um sistema (ou mais precisamente, a percepção de qualidade do usuário).
---
layout: false
class: inverse, middle

A usabilidade compreende as seguintes áreas

• Recursos do sistema de aprendizagem. Se o usuário não estiver familiarizado com um sistema específico ou com um aspecto específico dele, o que o sistema pode fazer para facilitar a tarefa de aprender? Isso pode incluir o fornecimento de recursos de ajuda.
---
layout: false
class: inverse, middle


• Usando um sistema de forma eficiente. O que o sistema pode fazer para tornar o usuário mais eficiente em sua operação? Isso pode incluir a capacidade de o usuário redirecionar o sistema após emitir um comando. Por exemplo, o usuário pode querer suspender uma tarefa, executar várias operações e, em seguida, retomar essa tarefa.
---
layout: false
class: inverse, middle

• Minimizar o impacto de erros.O que o sistema pode fazer para que um erro do usuário tenha um impacto mínimo? Por exemplo, o usuário pode cancelar um comando emitido incorretamente.
---
layout: false
class: inverse, middle

• Adaptação do sistema às necessidades do usuário. Como o usuário (ou o próprio sistema) pode se adaptar para facilitar a tarefa do usuário? Por exemplo, o sistema pode preencher automaticamente URLs com base nas entradas anteriores de um usuário.
---
layout: false
class: inverse, middle

• Aumentar a confiança e a satisfação. O que o sistema faz para dar ao usuário a confiança de que a ação correta está sendo executada? Por exemplo, fornecer feedback indicando que o sistema está executando uma tarefa de longa duração e até que ponto a tarefa é concluída aumentará a confiança do usuário no sistema.
---
layout: false
class: inverse, middle

.1 Cenário geral de usabilidade

As partes dos cenários gerais de usabilidade são as seguintes:
• Fonte de estimulo. O usuário final (que pode estar em uma função especializada, como um administrador de sistema ou rede) é sempre a fonte do estímulo à usabilidade.

• estímulo. O estímulo é que o usuário final deseja usar um sistema com eficiência, aprender a usá-lo, minimizar o impacto de erros, adaptar o sistema ou configurá-lo.
---
layout: false
class: inverse, middle

• meio ambiente. As ações do usuário relacionadas à usabilidade sempre ocorrem no tempo de execução ou no tempo de configuração do sistema.
---
layout: false
class: inverse, middle

• Artefato.O artefato é o sistema ou a parte específica do sistema com o qual o usuário está interagindo.
---
layout: false
class: inverse, middle

• Resposta.O sistema deve fornecer ao usuário os recursos necessários ou antecipar suas necessidades.
---
layout: false
class: inverse, middle

• medir a resposta. A resposta é medida pelo tempo da tarefa, número de erros, número de tarefas realizadas, satisfação do usuário, ganho de conhecimento do usuário, proporção de operações bem-sucedidas em relação ao total de operações ou quantidade de tempo ou dados perdidos quando ocorre um erro.
---
layout: false
class: inverse, middle, center
![Figura 11.1](image01.png)

A Tabela 11.1 enumera os elementos do cenário geral que caracterizam a usabilidade.

---
layout: false
class: inverse, middle, center
![Figura 11.2](image02.png)

Figura 11.1 fornece um exemplo de cenário de usabilidade concreto que você pode gerar usando a Tabela 11.1: O usuário baixa um novo aplicativo e o está usando produtivamente após dois minutos de experimentação.

---
layout: false
class: inverse, middle

11.2. Táticas para a usabilidade

Lembre-se de que a usabilidade se preocupa com a facilidade com que o usuário realiza uma tarefa desejada, bem como com o tipo de suporte que o sistema fornece ao usuário. Pesquisadores em interação humano-computador usaram os termos iniciativa do usuário iniciativa do, sistema e iniciativa mista para descrever qual dos pares humano-computador toma a iniciativa de executar determinadas ações e como a interação ocorre.
---
layout: false
class: inverse, middle

Os cenários de usabilidade podem combinar iniciativas de ambas as perspectivas. Por exemplo, ao cancelar um comando, o usuário emite um cancelamento - iniciativa do usuário - e o sistema responde. Durante o cancelamento, no entanto, o sistema pode apresentar um indicador de progresso - iniciativa do sistema. Assim, o cancelamento pode demonstrar iniciativa mista. Usamos essa distinção entre usuário e iniciativa do sistema para discutir as táticas que o arquiteto usa para alcançar os vários cenários.
---
layout: false
class: inverse, middle, center
![Figura 11.3](image03.png)

A Figura 11.2 mostra o objetivo do conjunto de táticas de usabilidade em tempo de execução.


---
layout: false
class: inverse, middle

Texto adicional: Separe a interface do usuário!

Uma das coisas mais úteis que um arquiteto pode fazer para tornar um sistema utilizável é facilitar a experimentação com a interface do usuário através da construção de protótipos rápidos. Construir um protótipo, ou vários protótipos, para permitir que usuários reais experimentem a interface e dê seus comentários, paga enormes dividendos. A melhor maneira de fazer isso é projetar o software para que a interface do usuário possa ser alterada rapidamente.
---
layout: false
class: inverse, middle

As táticas de modificação que vimos apoiam perfeitamente esse objetivo, especialmente as seguintes:

• Aumentar a coerência semântica, encapsular e co-localizar responsabilidades relacionadas, que localizam as responsabilidades da interface do usuário em um único local
---
layout: false
class: inverse, middle

• Restringir dependências, o que minimiza o efeito cascata para outro software quando a interface do usuário é alterada

• Adiar a ligação, que permite fazer escolhas críticas da interface do usuário sem precisar recodificar
---
layout: false
class: inverse, middle

Adiar a ligação é especialmente útil aqui, porque você pode esperar que a interface do usuário do seu produto sofra pressão para mudar durante os testes e mesmo depois vai ao mercado.
---
layout: false
class: inverse, middle

As ferramentas de geração de interface com o usuário são consistentes com essas táticas; a maioria produz um único módulo com uma interface abstrata para o restante do software. Muitos oferecem a capacidade de alterar a interface do usuário após o tempo de compilação. Você pode fazer sua parte restringindo as dependências no módulo gerado, caso decida adotar uma ferramenta diferente posteriormente.
---
layout: false
class: inverse, middle

Muito trabalho em diferentes padrões de separação da interface do usuário ocorreu nas décadas de 80 e 90. Com o advento da Web e a modernização do padrão MVC (Model-View-Controller) para refletir as interfaces da Web, o MVC se tornou o padrão de separação dominante. Agora, o padrão MVC está incorporado em uma ampla variedade de estruturas diferentes. O MVC facilita o fornecimento de várias visualizações dos dados, dando suporte à iniciativa do usuário, como discutiremos a seguir.
---
layout: false
class: inverse, middle

Muitas vezes, os atributos de qualidade estão em conflito entre si. Usabilidade e modificabilidade, por outro lado, geralmente se complementam, porque uma das melhores maneiras de tornar um sistema mais utilizável é modificá-lo. No entanto, esse nem sempre é o caso. Em muitos sistemas, as regras de negócios conduzem a interface do usuário - por exemplo, especificando como validar entrada. Para realizar essa validação, a interface do usuário pode precisar chamar um servidor (o que pode afetar negativamente o desempenho). Para contornar essa penalidade de desempenho, o arquiteto pode optar por duplicar essas regras no cliente e no servidor, o que dificulta a evolução. Infelizmente, a vida do arquiteto nunca é fácil!
---
layout: false
class: inverse, middle

Existe uma conexão entre a conquista de usabilidade e modificabilidade. O processo de design da interface do usuário consiste em gerar e testar um design da interface do usuário. As deficiências no design são corrigidas e o processo se repete. Se a interface do usuário já tiver sido construída como uma parte do sistema, o sistema deverá ser modificado para refletir o design mais recente. Daí a conexão com modificabilidade. Essa conexão resultou em padrões padrão para suportar o design da interface do usuário.
---
layout: false
class: inverse, middle

Apoiar a iniciativa do usuário

Depois que um sistema está em execução, a usabilidade é aprimorada, fornecendo ao usuário feedback sobre o que o sistema está fazendo e permitindo que o usuário faça as respostas apropriadas. Por exemplo, as táticas descritas a seguir: cancelar, desfazer, pausar / retomar e agregar. Ajudam o usuário a corrigir erros ou a ser mais eficiente.
---
layout: false
class: inverse, middle

O arquiteto cria uma resposta para a iniciativa do usuário, enumerando e alocando as responsabilidades do sistema para responder ao comando do usuário. Aqui estão alguns exemplos comuns de iniciativa do usuário:

• Cancelar. Quando o usuário emite um comando de cancelamento, o sistema deve ouvi-lo (portanto, há a responsabilidade de ter um ouvinte constante que não seja bloqueado pelas ações do que estiver sendo cancelado); o comando que está sendo cancelado deve ser encerrado; quaisquer recursos usados ​​pelo comando cancelado devem ser liberados; e os componentes que estão colaborando com o comando cancelado devem ser informados para que eles também possam tomar as medidas apropriadas.
---
layout: false
class: inverse, middle

• Undo.Para dar suporte à capacidade de desfazer, o sistema deve manter uma quantidade suficiente de informações sobre o estado do sistema para que um estado anterior possa ser restaurado, a pedido do usuário. Esse registro pode estar na forma de “instantâneos” do estado - por exemplo, pontos de verificação - ou como um conjunto de operações reversíveis. Nem todas as operações podem ser revertidas facilmente: por exemplo, alterar todas as ocorrências da letra "a" para a letra "b" em um documento não pode ser revertida alterando todas as instâncias de "b" para "a", porque algumas dessas instâncias de "b" pode ter existido antes da alteração original. Nesse caso, o sistema deve manter um registro mais elaborado da alteração. Obviamente, algumas operações, como tocar uma campainha (alerta do sistema), não podem ser desfeitas.
---
layout: false
class: inverse, middle

• Pausar / retomar. Quando um usuário inicia uma operação de longa duração - por exemplo, baixando um arquivo grande ou um conjunto de arquivos de um servidor - geralmente é útil fornecer a capacidade de pausar e retomar a operação. Pausar efetivamente uma operação de longa execução requer a capacidade de liberar recursos temporariamente para que eles possam ser realocados para outras tarefas.
---
layout: false
class: inverse, middle

• Agregar. Quando um usuário está executando operações repetitivas ou operações que afetam um grande número de objetos da mesma maneira, é útil fornecer a capacidade de agregar os objetos de nível inferior em um único grupo, para que a operação possa ser aplicada ao grupo, liberando assim o usuário da labuta (e do potencial de erros) de executar a mesma operação repetidamente. Por exemplo, agregue todos os objetos em um slide e altere o texto para a fonte de 14 pontos.
---
layout: false
class: inverse, middle

Iniciativa do sistema de suporte

Quando o sistema toma a iniciativa, deve confiar em um modelo do usuário, na tarefa executada pelo usuário ou no próprio estado do sistema. Cada modelo requer vários tipos de entrada para realizar sua iniciativa. As iniciativa do sistema de suporte táticas são aquelas que identificam os modelos que o sistema usa para prever seu próprio comportamento ou a intenção do usuário. O encapsulamento dessas informações facilitará sua adaptação ou modificação. A adaptação e modificação podem ser dinamicamente baseadas no comportamento passado do usuário ou offline durante o desenvolvimento. Essas táticas são as seguintes:
---
layout: false
class: inverse, middle
• Manter o modelo de tarefa. O modelo de tarefa é usado para determinar o contexto para que o sistema possa ter uma ideia do que o usuário está tentando e fornecer assistência. Por exemplo, saber que as frases começam com letras maiúsculas permitiria que um aplicativo corrija uma letra minúscula nessa posição.

---
layout: false
class: inverse, middle
• Manter modelo de usuário.Esse modelo representa explicitamente o conhecimento do usuário sobre o sistema, o comportamento do usuário em termos de tempo de resposta esperado e outros aspectos específicos de um usuário ou de uma classe de usuários. Por exemplo, a manutenção de um modelo de usuário permite que o sistema acompanhe a seleção do mouse para que nem todo o documento seja selecionado quando a rolagem for necessária. Ou um modelo pode controlar a quantidade de assistência e sugestões fornecidas automaticamente a um usuário. Um caso especial dessa tática é comumente encontrado na interface da personalização do usuário, em que um usuário pode modificar explicitamente o modelo de usuário do sistema.
---
layout: false
class: inverse, middle

• Manter modelo do sistema.Aqui o sistema mantém um modelo explícito de si mesmo. Isso é usado para determinar o comportamento esperado do sistema, para que o feedback apropriado possa ser dado ao usuário. Uma manifestação comum de um modelo de sistema é uma barra de progresso que prevê o tempo necessário para concluir a atividade atual.
---
layout: false
class: inverse, middle, center
![Figura 11.4](image04.png)

A Figura 11.3 mostra um resumo das táticas para alcançar a usabilidade.

---
layout: false
class: inverse, middle
Tabela 11.2 é uma lista de verificação para apoiar o processo de design e análise para usabilidade.
---
layout: false
class: inverse, middle, center
![Figura 11.5](image05.png)

---
layout: false
class: inverse, middle, center
![Figura 11.6](image06.png)

---
layout: false
class: inverse, middle

11.4. Resumo

O suporte arquitetural à usabilidade envolve permitir que o usuário tome a iniciativa - em circunstâncias como cancelar um comando de longa execução ou desfazer um comando concluído - e agregar dados e comandos.
---
layout: false
class: inverse, middle

Para poder prever respostas do usuário ou do sistema, o sistema deve manter um modelo explícito do usuário, do sistema e da tarefa.
---
layout: false
class: inverse, middle

Existe uma forte relação entre o suporte ao processo de design da interface com o usuário e o suporte à modificabilidade; essa relação é promovida por padrões que impõem a separação da interface com o usuário do resto do sistema, como o padrão MVC.

---
layout: false
class:inverse,center,middle

DÚVIDAS/FIM

contato: marc.queiroz at unifil.br


    </textarea>
    <script>
    document.write('<script src="http://' + (location.host || 'localhost').split(':')[0] + ':35729/livereload.js?snipver=1"></' + 'script>')
</script>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({ ratio: '16:10' });
    </script>
  </body>
</html>
